% According to the HPA (examination office) you are obligated to write
% an abstract in English and German

\pagestyle{plain}
\pagenumbering{Roman}


% Acknowledgement EN
\begin{quote}
	\textbf{\Large Acknowledgement}\\\\
Language models has shown state-of-the-art performances in various natural language  processing task. Recent research has shown their weakness against adversarial attacks, where imperceptible noise in text can lead model to behave unexpectedly and severely degraded their performance under attack. Furthermore, the research towards defensive mechanism is comparatively less studied topic than generating prominent adversarial attacks. In this master thesis, a semi-supervised approach of fine-tuning is proposed which can lead to robust language model without compromising with original accuracy. An experiment was conducted to compare the performance of model fine-tuned using conventional method and proposed method. The experiment was performed using BERT and DistilBERT language models on two datasets.  As per experiment, the proposed approach demonstrated 0-2\% and  20-30\%  improvement in original accuracy and  accuracy under attacks over conventional method, respectively.

\end{quote}
