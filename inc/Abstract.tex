% According to the HPA (examination office) you are obligated to write
% an abstract in English and German

\pagestyle{plain}
\pagenumbering{Roman}

% Abstract DE
\begin{quote}
\textbf{\Large Zusammenfassung}\\\\
Sprachmodelle haben bei verschiedenen Aufgaben der natürlichen Sprachverarbeitung Spitzenleistungen erbracht. Jüngste Forschungen haben gezeigt, dass diese Modelle Schwächen gegenüber feindlichen Angriffen aufweisen, bei denen unmerkliches Rauschen im Text dazu führen kann, dass sich das Modell unerwartet verhält und seine Leistung bei Angriffen stark beeinträchtigt wird. Darüber hinaus ist die Erforschung von Verteidigungsmechanismen ein vergleichsweise wenig erforschtes Thema im Vergleich zur Generierung prominenter gegnerischer Angriffe. In dieser Masterarbeit wird ein halbüberwachter Ansatz der Feinabstimmung vorgeschlagen, der zu einem robusten Sprachmodell führen kann, ohne die ursprüngliche Genauigkeit zu beeinträchtigen. Es wurde ein Experiment durchgeführt, um die Leistung des mit der konventionellen Methode und der vorgeschlagenen Methode feinabgestimmten Modells zu vergleichen. Das Experiment wurde mit den Sprachmodellen BERT und DistilBERT auf zwei Datensätzen durchgeführt.  Das Experiment zeigte, dass der vorgeschlagene Ansatz die ursprüngliche Genauigkeit um 0 $\sim$ 2\% und die Genauigkeit unter Angriffen um 20 $\sim$ 30\% verbessert.
pending
\end{quote}

\newpage

% Abstract EN
\begin{quote}
	\textbf{\Large Abstract}\\\\
Language models have shown state-of-the-art performances in various natural language  processing tasks. Recent research has shown their weakness against adversarial attacks, where imperceptible noise in text can lead model to behave unexpectedly and severely degraded their performance under attack. Furthermore, the research towards defensive mechanism is comparatively less studied topic than generating prominent adversarial attacks. In this master thesis, a semi-supervised approach of fine-tuning is proposed which can lead to robust language model without compromising with original accuracy. An experiment was conducted to compare the performance of model  that is fine-tuned using conventional and proposed method. This report also contribute in revealing the scope of improvements in language models.
The experiment was conducted using BERT and DistilBERT language models on two datasets.  As per experiment, the proposed approach shows  0$\sim$2\% and  20$\sim$30\%  improvement in original accuracy and  accuracy under attacks over conventional method, respectively. 

\end{quote}
